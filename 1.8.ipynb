{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\ndf=pd.read_csv(\"../input/final_train_5.csv\")\ndf=df.drop(\"Unnamed: 0\",1)\ndf.head()\nX = df.iloc[:,1:]\nX.head()\ny = pd.DataFrame(df.iloc[:,0])\ny.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abc2a3b5e3d36f224542b1927f84b7e5f74f7f59"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\ndef cross_validation_function4(X,y,models,fold,w):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        \n        y_true=pd.Series(dfytest.iloc[:,0])\n        \n        model1.fit(dfxtrain,dfytrain.values.ravel())\n        model2.fit(dfxtrain,dfytrain.values.ravel())\n        model3.fit(dfxtrain,dfytrain.values.ravel())\n        model4.fit(dfxtrain,dfytrain.values.ravel())\n        model5.fit(dfxtrain,dfytrain.values.ravel())\n        model6.fit(dfxtrain,dfytrain.values.ravel())\n        model7.fit(dfxtrain,dfytrain.values.ravel())\n        model8.fit(dfxtrain,dfytrain.values.ravel())\n        model9.fit(dfxtrain,dfytrain.values.ravel())\n        model10.fit(dfxtrain,dfytrain.values.ravel())\n\n        y_pred1=model1.predict(dfxtest)\n        y_pred2=model2.predict(dfxtest)\n        y_pred3=model3.predict(dfxtest)\n        y_pred4=model4.predict(dfxtest)\n        y_pred5=model5.predict(dfxtest)\n        y_pred6=model6.predict(dfxtest)\n        y_pred7=model7.predict(dfxtest)\n        y_pred8=model8.predict(dfxtest)\n        y_pred9=model9.predict(dfxtest)\n        y_pred10=model10.predict(dfxtest)\n            \n            \n        p=[0]*11\n        for i in range(0,len(w)):\n            p[i+1]=w[i]\n        \n        y_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n        sc=np.mean(np.abs((y_true - y_pred) / y_true))\n        scores.append(sc)\n        print(\"        FOLD  :\",f)\n        print(\"        Score :\", sc)\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6dd35dcf5cc55ecb38528774da5366bda2c26bf"
      },
      "cell_type": "code",
      "source": "w=[0.1111111111111111]*10\nw[5]=0\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\n\n\nmodel1.fit(X,y.values.ravel())\nmodel2.fit(X,y.values.ravel())\nmodel3.fit(X,y.values.ravel())\nmodel4.fit(X,y.values.ravel())\nmodel5.fit(X,y.values.ravel())\nmodel6.fit(X,y.values.ravel())\nmodel7.fit(X,y.values.ravel())\nmodel8.fit(X,y.values.ravel())\nmodel9.fit(X,y.values.ravel())\nmodel10.fit(X,y.values.ravel())\n\ny_pred1=model1.predict(X)\ny_pred2=model2.predict(X)\ny_pred3=model3.predict(X)\ny_pred4=model4.predict(X)\ny_pred5=model5.predict(X)\ny_pred6=model6.predict(X)\ny_pred7=model7.predict(X)\ny_pred8=model8.predict(X)\ny_pred9=model9.predict(X)\ny_pred10=model10.predict(X)\n\ny_true=pd.Series(y.iloc[:,0])\np=[0]*11\nfor i in range(0,len(w)):\n    p[i+1]=w[i]\ny_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n\nprint(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\nlistofmodels=[model1,model2,model3,model4,model5,model6,model7,model8,model9,model10]\n\n\nnewscore=cross_validation_function4(X,y,listofmodels,5,w)\nprint(\"Testing Cross Validation Error: \",newscore)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cross_validation_function3(X,y,model,fold):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        model.fit(dfxtrain,dfytrain.values.ravel())\n        y_pred=model.predict(dfxtest)\n        y_true=pd.Series(dfytest.iloc[:,0])\n#         pd.Series(y.iloc[:,0])\n#         print(y_true)\n#         print(y_pred)\n        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n#         print(\"        FOLD \",f)\n#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3160e0255970377056c25b67d1a53b1ea0560ec"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nimport numpy as np\nboosting_type_set1=['gbdt','gbrt','dart']\nboosting_type_set2=['gbdt','dart']\nm=20\nn=31\ntree_learner_set =['serial','feature','data','voting']\nsc=[]\nmin = 1\nfor nest in range(1000,100,-50):\n    for d in range(7,10):\n        for l in np.arange(0.08,0.23,0.01):\n            for b in boosting_type_set2:\n                for n in range(25,48,4):\n                    for m in range(5,30,5):\n                        for iter in range(100,500,100):\n#                 for t in tree_learner_set:\n                            lgbm = LGBMRegressor(boosting_type=b, num_leaves=n, max_depth=d, learning_rate=l, n_estimators=nest,objective='regression',metric='mape',tree_learner='serial',min_data_in_leaf=m,random_state=30, n_jobs=-1 )\n                            print(\"N Estimators is : \",nest)\n                            print(\"Depth =\",d)\n                            print(\"Learning Rate: \",l)\n                            print(\"b = \",b)\n                            print(\"no of leaves is :\",n)\n                            print(\"minimum data in leaf =\",m)\n                            print(\"Iterations is : \",iter)\n        #                     print(\"tree learner set is : \",t)\n\n                #             print(\"Booster : \",b)\n                            newscore=cross_validation_function3(X,y,lgbm,5)\n                            print(\"\\n\\n\")\n                            sc.append(newscore)\n                            if(newscore<min):\n                                min=newscore\n                #                 print(\"Min CHANGED TO : \",min,\"AND  n est = \",nest,\"l = \",l)\n                                print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\"b = \",b,\"no of leaves = \",n,\"minimum data in leaf= \",m,\"iterations =\",iter)\n                                print(\"\\n\\n\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5838dc5c2ec1ebe507e4bdb750698d975e4dac44"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cb8f6ab21624b501cfd155c67317ac88ca0db6f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd005a59253265e85a0bb9cbd7053ad2e133f5e7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96b0595b8923ec8c20e71b9efd8bf354f8ac610f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "694c62ff9a505e9b211a995b829b40b54c98aea4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c17a4866bdf00403ce1b28f26de03e32028764ed"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d29a3ff65c1a303756d64c6f72db4a96c710db5c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a50c1afd6bd2ff3651ab8b8b7cf86a1a6a4682fb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "610d710c08f019629f5038a8be21c9e5a50cce00"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ca58c663eb52a193ea6a1dc3b533bfa04333b40"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b11d8461ccfcc4881d3aa5b28dd22c66bb88ebf5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a6b4e4a0b0c61699081ab4fe1ed2a46cd6a0a08"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}