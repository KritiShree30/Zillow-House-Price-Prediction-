{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\ndf=pd.read_csv(\"../input/final_train_5.csv\")\ndf=df.drop(\"Unnamed: 0\",1)\ndf.head()\nX = df.iloc[:,1:]\nX.head()\ny = pd.DataFrame(df.iloc[:,0])\ny.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a130d632e63d30d3d7ac53102658d6a2bbfd8d86"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\ndef cross_validation_function4(X,y,models,fold,w):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        \n        y_true=pd.Series(dfytest.iloc[:,0])\n        \n        model1.fit(dfxtrain,dfytrain.values.ravel())\n        model2.fit(dfxtrain,dfytrain.values.ravel())\n        model3.fit(dfxtrain,dfytrain.values.ravel())\n        model4.fit(dfxtrain,dfytrain.values.ravel())\n        model5.fit(dfxtrain,dfytrain.values.ravel())\n        model6.fit(dfxtrain,dfytrain.values.ravel())\n        model7.fit(dfxtrain,dfytrain.values.ravel())\n        model8.fit(dfxtrain,dfytrain.values.ravel())\n        model9.fit(dfxtrain,dfytrain.values.ravel())\n        model10.fit(dfxtrain,dfytrain.values.ravel())\n\n        y_pred1=model1.predict(dfxtest)\n        y_pred2=model2.predict(dfxtest)\n        y_pred3=model3.predict(dfxtest)\n        y_pred4=model4.predict(dfxtest)\n        y_pred5=model5.predict(dfxtest)\n        y_pred6=model6.predict(dfxtest)\n        y_pred7=model7.predict(dfxtest)\n        y_pred8=model8.predict(dfxtest)\n        y_pred9=model9.predict(dfxtest)\n        y_pred10=model10.predict(dfxtest)\n            \n            \n        p=[0]*11\n        for i in range(0,len(w)):\n            p[i+1]=w[i]\n        \n        y_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n        sc=np.mean(np.abs((y_true - y_pred) / y_true))\n        scores.append(sc)\n        print(\"        FOLD  :\",f)\n        print(\"        Score :\", sc)\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d69d2e7b71ce030fe68d9f651a7fa8b5e27f3971"
      },
      "cell_type": "code",
      "source": "w=[0.1111111111111111]*10\nw[4]=0\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\n\n\nmodel1.fit(X,y.values.ravel())\nmodel2.fit(X,y.values.ravel())\nmodel3.fit(X,y.values.ravel())\nmodel4.fit(X,y.values.ravel())\nmodel5.fit(X,y.values.ravel())\nmodel6.fit(X,y.values.ravel())\nmodel7.fit(X,y.values.ravel())\nmodel8.fit(X,y.values.ravel())\nmodel9.fit(X,y.values.ravel())\nmodel10.fit(X,y.values.ravel())\n\ny_pred1=model1.predict(X)\ny_pred2=model2.predict(X)\ny_pred3=model3.predict(X)\ny_pred4=model4.predict(X)\ny_pred5=model5.predict(X)\ny_pred6=model6.predict(X)\ny_pred7=model7.predict(X)\ny_pred8=model8.predict(X)\ny_pred9=model9.predict(X)\ny_pred10=model10.predict(X)\n\ny_true=pd.Series(y.iloc[:,0])\np=[0]*11\nfor i in range(0,len(w)):\n    p[i+1]=w[i]\ny_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n\nprint(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\nlistofmodels=[model1,model2,model3,model4,model5,model6,model7,model8,model9,model10]\n\n\nnewscore=cross_validation_function4(X,y,listofmodels,5,w)\nprint(\"Testing Cross Validation Error: \",newscore)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cross_validation_function3(X,y,model,fold):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        model.fit(dfxtrain,dfytrain.values.ravel())\n        y_pred=model.predict(dfxtest)\n        y_true=pd.Series(dfytest.iloc[:,0])\n#         pd.Series(y.iloc[:,0])\n#         print(y_true)\n#         print(y_pred)\n        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n#         print(\"        FOLD \",f)\n#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bba83d21293d7fc4e1ed141204e9c0194255794"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nimport numpy as np\nboosting_type_set1=['gbdt','gbrt','dart']\nboosting_type_set2=['gbdt','dart']\nm=20\nn=31\ntree_learner_set =['serial','feature','data','voting']\nsc=[]\nmin = 1\nfor nest in range(1000,100,-100):\n    for d in range(7,10):\n        for l in np.arange(0.1,0.5,0.01):\n            for b in boosting_type_set2:\n                for n in range(25,48,4):\n#                 for t in tree_learner_set:\n#         for l in [0.001,0.01,0.1,1]:\n                    lgbm = LGBMRegressor(boosting_type=b, num_leaves=n, max_depth=d, learning_rate=l, n_estimators=nest,objective='regression',metric='mape',tree_learner='serial',min_data_in_leaf=m,random_state=30, n_jobs=-1 )\n                    print(\"N Estimators is : \",nest)\n                    print(\"Depth =\",d)\n                    print(\"Learning Rate: \",l)\n                    print(\"b = \",b)\n                    print(\"no of leaves is :\",n)\n#                     print(\"tree learner set is : \",t)\n\n        #             print(\"Booster : \",b)\n                    newscore=cross_validation_function3(X,y,lgbm,5)\n                    print(\"\\n\\n\")\n                    sc.append(newscore)\n                    if(newscore<min):\n                        min=newscore\n        #                 print(\"Min CHANGED TO : \",min,\"AND  n est = \",nest,\"l = \",l)\n                        print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\"b = \",b,\"no of leaves = \",n)\n                        print(\"\\n\\n\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2ec08bb071fd66befc8f3ac0ee194f90eca2c1f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f7382733e1a188a082cbb76b54e52fdaa0c7155"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e516d75d3633fee8dbadbbcb3f9cf0c3a66f5225"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d94c85b691d2e7337fe3dca072862f934aff4ad3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d52ba375642335b89e3fd3d9b7fb582882d4728"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6446ed37eacdc78b8f02bb43655d1a76bd9e862c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f29c6e32abeba9ac4f245bab5db858e79258133"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f45dd07490dd79c0ac39525d9afc9b01a5f28ad3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "519c94b23f6f863d2db4f5536c727309f598d3f0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f3c3db66cd342aad06634a84fa17d4b175801e7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "708c695337c22701805239c5884d8c35eb87fbf5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "375b5d97c321e7aa20038acefc669056b86ae272"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}