{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\ndf=pd.read_csv(\"../input/final_train_5.csv\")\ndf=df.drop(\"Unnamed: 0\",1)\ndf.head()\nX = df.iloc[:,1:]\nX.head()\ny = pd.DataFrame(df.iloc[:,0])\ny.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e56b0ed55c842c5a7ab9bbda27139ff58c0a8f67"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\ndef cross_validation_function4(X,y,models,fold,w):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        \n        y_true=pd.Series(dfytest.iloc[:,0])\n        \n        model1.fit(dfxtrain,dfytrain.values.ravel())\n        model2.fit(dfxtrain,dfytrain.values.ravel())\n        model3.fit(dfxtrain,dfytrain.values.ravel())\n        model4.fit(dfxtrain,dfytrain.values.ravel())\n        model5.fit(dfxtrain,dfytrain.values.ravel())\n        model6.fit(dfxtrain,dfytrain.values.ravel())\n        model7.fit(dfxtrain,dfytrain.values.ravel())\n        model8.fit(dfxtrain,dfytrain.values.ravel())\n        model9.fit(dfxtrain,dfytrain.values.ravel())\n        model10.fit(dfxtrain,dfytrain.values.ravel())\n\n        y_pred1=model1.predict(dfxtest)\n        y_pred2=model2.predict(dfxtest)\n        y_pred3=model3.predict(dfxtest)\n        y_pred4=model4.predict(dfxtest)\n        y_pred5=model5.predict(dfxtest)\n        y_pred6=model6.predict(dfxtest)\n        y_pred7=model7.predict(dfxtest)\n        y_pred8=model8.predict(dfxtest)\n        y_pred9=model9.predict(dfxtest)\n        y_pred10=model10.predict(dfxtest)\n            \n            \n        p=[0]*11\n        for i in range(0,len(w)):\n            p[i+1]=w[i]\n        \n        y_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n        sc=np.mean(np.abs((y_true - y_pred) / y_true))\n        scores.append(sc)\n        print(\"        FOLD  :\",f)\n        print(\"        Score :\", sc)\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f7b164f59fdad3ddaf55935e28156290e2f8df8"
      },
      "cell_type": "code",
      "source": "w=[0.1111111111111111]*10\nw[3]=0\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\n\n\nmodel1.fit(X,y.values.ravel())\nmodel2.fit(X,y.values.ravel())\nmodel3.fit(X,y.values.ravel())\nmodel4.fit(X,y.values.ravel())\nmodel5.fit(X,y.values.ravel())\nmodel6.fit(X,y.values.ravel())\nmodel7.fit(X,y.values.ravel())\nmodel8.fit(X,y.values.ravel())\nmodel9.fit(X,y.values.ravel())\nmodel10.fit(X,y.values.ravel())\n\ny_pred1=model1.predict(X)\ny_pred2=model2.predict(X)\ny_pred3=model3.predict(X)\ny_pred4=model4.predict(X)\ny_pred5=model5.predict(X)\ny_pred6=model6.predict(X)\ny_pred7=model7.predict(X)\ny_pred8=model8.predict(X)\ny_pred9=model9.predict(X)\ny_pred10=model10.predict(X)\n\ny_true=pd.Series(y.iloc[:,0])\np=[0]*11\nfor i in range(0,len(w)):\n    p[i+1]=w[i]\ny_pred=(p[1]*y_pred1 + p[2]*y_pred2 + p[3]*y_pred3 + p[4]*y_pred4 + p[5]*y_pred5 + p[6]*y_pred6 + p[7]*y_pred7 + p[8]*y_pred8 + p[9]*y_pred9 + p[10]*y_pred10)\n\nprint(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n\nmodel1 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel2= LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel3 = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel4 = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel5 = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel6 = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\nmodel7 = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\nmodel8 = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\nmodel9 = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\nmodel10 = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n\nlistofmodels=[model1,model2,model3,model4,model5,model6,model7,model8,model9,model10]\n\n\nnewscore=cross_validation_function4(X,y,listofmodels,5,w)\nprint(\"Testing Cross Validation Error: \",newscore)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cross_validation_function3(X,y,model,fold):\n    size=int(len(X)/fold)\n    l=0\n    u=size\n    scores=[]\n    for f in range(fold):\n#         print(\"l =\",l,\"u =\",u,\"\")\n        dfxtest=X.iloc[l:u,:]\n        dfytest=y.iloc[l:u,:]\n        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n        model.fit(dfxtrain,dfytrain.values.ravel())\n        y_pred=model.predict(dfxtest)\n        y_true=pd.Series(dfytest.iloc[:,0])\n#         pd.Series(y.iloc[:,0])\n#         print(y_true)\n#         print(y_pred)\n        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n#         print(\"        FOLD \",f)\n#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n        l=l+size\n        u=u+size\n    print(\"Final score is: \",np.mean(scores))\n    return np.mean(scores)\n      \n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5d2555a3246479b8cd54e9a2cd4038ae8dfb635"
      },
      "cell_type": "code",
      "source": "from lightgbm import LGBMRegressor\nimport numpy as np\nboosting_type_set1=['gbdt','gbrt','dart']\nboosting_type_set2=['gbdt','dart']\nm=20\nn=31\ntree_learner_set =['serial','feature','data','voting']\nsc=[]\nmin = 1\nfor nest in range(1000,100,-100):\n    for d in range(7,10):\n        for l in np.arange(0.001,0.21,0.001):\n            for iter in range(100,1200,1000):\n                for n in range(25,48,4):\n                    for b in boosting_type_set2:\n#                 for n in range(25,48,4):\n#                     for m in range(5,30,5):\n#                 for t in tree_learner_set:\n                        lgbm = LGBMRegressor(num_iterations=iter,boosting_type=b, num_leaves=n, max_depth=d, learning_rate=l, n_estimators=nest,objective='regression',metric='mape',tree_learner='serial',min_data_in_leaf=m,random_state=30, n_jobs=-1 )\n                        print(\"N Estimators is : \",nest)\n                        print(\"Depth =\",d)\n                        print(\"Learning Rate: \",l)\n                        print(\"b = \",b)\n                        print(\"NO of iterations :\",iter)\n                        print(\"no of leaves is :\",n)\n    #                     print(\"minimum data in leaf =\",m)\n        #                     print(\"tree learner set is : \",t)\n\n            #             print(\"Booster : \",b)\n                        newscore=cross_validation_function3(X,y,lgbm,5)\n                        print(\"\\n\\n\")\n                        sc.append(newscore)\n                        if(newscore<min):\n                            min=newscore\n            #                 print(\"Min CHANGED TO : \",min,\"AND  n est = \",nest,\"l = \",l)\n                            print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\"b = \",b,\"no of iterations = \",iter,\"no.of leaves = \",n)\n                            print(\"\\n\\n\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e410c632bc9308aaa3e7d2111e6be7931afe054d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "649e01b6c37b036df3fa6330b9e02b4d361598e9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7febfcebf5f78cb0cfe5a9aafe9fb3a9bbd8ad7d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bf1db8faaca5331f5be08d38c50d569d6306d4a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c98890a9902da0bfca5d3ead09414b3af904a5ab"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78c2164f193808c6139a06c3503d18e861cbc1e0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d157213e8c04dcd9d3cd2fd9e8ae7c91b7180a71"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d7af0361ba608f0b08114db623384d8c0034eb7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eec2968b0264d40da0a8a7b96e8059e354ea4d78"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84c7e0283ac26a83b520c493cff2392ecba9d967"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16f17ba40ef728deb08a6f891ca30b47defc4100"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1bbf978e6b3eec77e79d8f5d2b9bfad028284f34"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}